# ğŸ§  Chatbot RAG System using Ollama + ChromaDB

A simple Retrieval-Augmented Generation (RAG) chatbot built using:

- ğŸ¦™ Ollama (Local LLM & Embeddings)
- ğŸ—‚ ChromaDB (Vector Database)
- ğŸ” LangChain Text Splitter
- ğŸ Python
- ğŸ³ Docker (Optional)



---


---

## ğŸ“¸ Demo Preview

<p align="center">
  <img src="result.jpg" 
       alt="RAG Chatbot Terminal Output Demo" 
       width="850"
       style="border-radius:10px; box-shadow:0px 4px 15px rgba(0,0,0,0.2);" />
</p>

<p align="center">
  <em>Figure: Terminal output showing Retrieval-Augmented Generation (RAG) response using Ollama + ChromaDB</em>
</p>

---

---

---

## ğŸ“ Project Structure

```
chatbot/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â””â”€â”€ ollama-docker/
    â””â”€â”€ code/
        â”œâ”€â”€ articles.jsonl
        â”œâ”€â”€ chunking.py
        â”œâ”€â”€ chunking_langchain_ollama.py
        â”œâ”€â”€ rag_concept.py
        â”œâ”€â”€ vector_db.py
        â”œâ”€â”€ counter.py
        â”œâ”€â”€ counter.txt
        â”œâ”€â”€ example_code.py
        â”œâ”€â”€ simple.txt
        â”œâ”€â”€ chroma/
        â””â”€â”€ __pycache__/
```

---

## ğŸš€ Features

- ğŸ“š Reads data from `articles.jsonl`
- âœ‚ Splits text into chunks
- ğŸ”¢ Generates embeddings using `nomic-embed-text`
- ğŸ’¾ Stores vectors in ChromaDB
- ğŸ¤– Uses `qwen3:4b-instruct` for answering questions
- ğŸ“Š Tracks skipped sentences using counter system
- ğŸ” Retrieves top-k similar chunks

---

## ğŸ›  Requirements

- Python 3.11+
- Ollama installed locally
- Docker (optional)

---

## ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ¦™ Install Required Ollama Models

```bash
ollama pull nomic-embed-text
ollama pull qwen3:4b-instruct
```

---

## â–¶ï¸ Run the Project

Go to the code directory:

```bash
cd ollama-docker/code
```

Run the script:

```bash
python example_code.py
```

---

## âš™ï¸ How It Works

1. Load articles from JSONL file  
2. Split text into chunks  
3. Generate embeddings  
4. Store embeddings in ChromaDB  
5. Retrieve top relevant chunks  
6. Send context + question to LLM  
7. Generate final answer  

---

## ğŸ§® Counter System

The `counter.py` tracks:
- Number of skipped sentences  
- Number of processed lines  
- Maintains state in `counter.txt`  

---

## ğŸ“Š Example Output

```
Answer:
The House of Representatives elections will take place on March 5.
```

---

## ğŸ³ Docker Setup (Optional)

```bash
docker-compose up --build
```

---

## ğŸ§  Models Used

- Embedding Model: `nomic-embed-text`
- Chat Model: `qwen3:4b-instruct`

---

## ğŸ“Œ Future Improvements

- Add Web UI (Streamlit / FastAPI)
- Improve Retrieval Quality
- Add Memory System
- Deploy on VPS
- Connect to Frontend

---

## ğŸ‘¨â€ğŸ’» Author

Janak Rokaya 
Chatbot RAG Project  
Kathmandu Engineering College